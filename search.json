[
  {
    "objectID": "randomposts.html",
    "href": "randomposts.html",
    "title": "TIL/Random Notes",
    "section": "",
    "text": "This is a collection of random thoughts and things I’ve learned. For longer-form,regularly updated posts, visit the Blog page.\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nInference on HuggingFace\n\n\n\nshort-note\n\nhuggingface\n\ninference\n\ntext-to-image\n\nflux\n\n\n\nPlaying with the Inference Providers on HuggingFace\n\n\n\n\n\nFeb 5, 2025\n\n\nFarrukh Nauman\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nFrom Python to React: Using Claude Artifacts and ChatGPT Canvas to Build Apps\n\n\n\nshort-note\n\nwebapps\n\nreact\n\n\n\nLearn how to set up a modern web development environment: React, Node.js, and Vite.\n\n\n\n\n\nJan 26, 2025\n\n\nFarrukh Nauman\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\nUploading datasets to Hugging Face\n\n\n\nshort-note\n\nhuggingface\n\ndatasets\n\n\n\nHugging Face Datasets\n\n\n\n\n\nJan 26, 2025\n\n\nFarrukh Nauman\n\n2 min\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-11-20-llms-summary/index.html",
    "href": "posts/2023-11-20-llms-summary/index.html",
    "title": "Large Language Models: A Compact Guide",
    "section": "",
    "text": "This article is a work in progress because the field of LLMs is a work in progress. Additionally, I am unable to keep up with all the fantastic innovations in LLMs every couple of months. This article represents both my own learning experience and a compilation of things that I have tested and found to work well with my workflows.\n\nIn November, 2023, when I first wrote this article, GPT-4 with vision capabilities had just come out. Most competitors were playing catch-up with GPT-4 for most of 2023 and early 2024. By Summer 2024, Claude 3.5 Sonnet was released and immediately became the default LLM for coding assistants because of its superior performance over GPT-4/GPT-4o. Since September 2024, multiple reasoning models have been released triggered by the launch of OpenAI’s o1. Below article represents a high level summary of how LLMs work and I start by presenting my top choices for LLMs for various tasks, which changes every few months.\n\n\n\nBest models and tools I use:\n\nCode: Claude 3.5 Sonnet, DeepSeek-r1 (see also DeekSeekv3 - 93.1% of aider’s own code writes are using Deepseekv3)\nWriting: Gemini 2.0 Pro Experimental 02-05 - this has become my default model for writing. The only complaint I have is that it currently supports file attachments through the AI studio interface, but not the Gemini app.\nSpeech-to-Speech: OpenAI’s GPT-4o, Gemini 2.0 Flash - both seem to have a 30 min limit unfortunately.\nReasoning/Planning: OpenAI-o1, DeepSeek-r1, Gemini Flash Thinking Experimental 01-21, OpenAI-o3-mini - in that order. I am hoping OpenAI-o3 will be considerably better than OpenAI-o1 and o3-mini when it becomes available to Plus users.\nResearch: NotebookLM, Gemini Deep Research. One major limitation of these tools and LLMs in general (except Claude 3.5 Sonnet apparently) is that they use OCR to convert PDFs into text, which often does not capture the layout and structure of the document.\nIDEs/Agents: windsurf, aider, github copilot - in that order. I also tried cursor, which is arguably the most popular IDE right now for power users. I personally do not find it’s composer to be better than Windsurf’s cascade. The tab might be better though. Also, Windsurf costs $10/month while Cursor $20/month with differences in how many times you can call “premium models” (GPT-4o, Claude 3.5 Sonnet, DeepSeek-r1, etc.). I will report back on how [OpenHands](https://github.com/All-Hands-AI/OpenHands) (previously called OpenDevin) compares to the other tools listed here.\n\n(For text-to-image, imagen-3 by Google and flux-dev are my top choices.)\n\n\n\n\nAt their core, Language Models are designed to learn the probability distribution of word sequences. I like to think of LLM architectures as composed of three major components:\n\nInput: This covers tokenization and embedding on input text. Tokenization is a bottleneck especially for domain-specific languages. Frontier research is exploring alternative tokenization methods and tokenization-free approaches that I will write more about later.\nCore (self-attention): Multi-head self-attention, several layers of it with residual connection forms the core of the transformer architecture (attention is all you need). This is arguably the reason why LLMs are so powerful at understanding multiple meanings of the same word, and doing “in-context learning”.\nOutput: While earlier models were only focusing on the “pretraining” phase that literally just does next-token prediction, newer models involve extensive instruction tuning and reinforecement learning based approaches to force the model to learn how to generate coherent text over long sequences. Some recent work like DeepSeekv3 has made improvements in the pretraining phase where they introduced an auxiliary multi-token prediction loss instead of just using a single token prediction loss that is commonplace.\n\nI plan to extend the following discussion with more about the recent innovations in each of the three components: context extension through Rotary Position Embeddings (RoPE), performance improvements through Flash Attention, multi-token prediction, etc.\n\n\nBefore text can be processed by an LLM, it must be converted into numerical representations. This is the role of the tokenizer. Tokenizers break down text into smaller units called tokens, which can be words, subwords, or characters. Different LLMs often employ distinct tokenization methods, leading to fragmentation in the ecosystem. For example, OpenAI models utilize Byte-Pair Encoding (BPE), while T5 uses SentencePiece.\nTokenization as a Potential Bottleneck: Tokenization can be a performance bottleneck and introduce limitations, particularly in these scenarios:\n\nOut-of-Vocabulary (OOV) Tokens: Tokenizers typically have a fixed vocabulary size. Words not present in this vocabulary are treated as OOV tokens, often represented by a special &lt;unk&gt; token. A high number of OOV tokens can degrade model performance as the model has no learned representation for these words.\nAdaptability to New Languages: Models trained primarily on English may struggle to tokenize languages with different scripts or linguistic structures (e.g., Chinese, Urdu, Swahili).\nDomain-Specific Languages: Technical domains like programming languages (HTML, Python) or specialized fields (medicine, law) pose challenges. These domains have unique syntax, terminology, and structures that general-purpose tokenizers may not handle optimally. Currently, as a side project, I am trying to port some old fluid dynamics codes from Fortran 90 to Python and finding that some LLMs are worse at understanding Fortran 90 (arguably out of favor in the industry).\n\n\n\n\nBroadly speaking, this is the stand-out feature of the neural network based approaches as opposed to classical Markovian or n-gram like models: you can embed anything (language, audio, video, images, etc.) into a numerical representation that captures its semantic meaning. The numerical tokens are then transformed into dense vector representations by a learned embedding layer. These embeddings are not just arbitrary numbers; they are designed to capture the semantic meaning of the tokens. Tokens with similar meanings are positioned closer together in the embedding space. The size of the embedding vector (embedding dimension) is a hyperparameter, with modern LLMs often employing sizes of 2048 or larger. The increasing the embedding dimension can significantly increase the model size and computational complexity.\nPurpose: Embeddings serve as a crucial bridge, translating discrete tokens into a continuous vector space where semantic relationships can be mathematically modeled. Pre-trained LLMs leverage embeddings learned from vast amounts of text data, enabling them to capture general language understanding.\n\n\n\nThe self-attention mechanism is arguably the most significant innovation driving the power of modern LLMs. It allows each token in a sequence to “attend” to all other tokens, enabling the model to capture contextual relationships within the input. This is in contrast to earlier sequential models (like RNNs) which processed text token by token.\nHow Self-Attention Works (Simplified): Imagine each token as having three vectors associated with it: a Query, a Key, and a Value. For each token, the model calculates an “attention score” by comparing its Query vector to the Key vectors of all other tokens in the sequence. These scores determine how much attention each token should pay to others when constructing its contextual representation. The Value vectors are then weighted by these attention scores and aggregated to produce the context-aware representation for each token.\nMultiple Attention Heads: Most LLMs utilize multi-head attention, meaning they perform the self-attention process multiple times in parallel with different sets of Query, Key, and Value matrices. This allows the model to learn diverse types of relationships and attend to different aspects of the input simultaneously, enriching the contextual understanding.\nComputational Considerations: It’s important to note that the computational complexity of self-attention is quadratic with respect to the sequence length (O(n2)), where n is the number of tokens. This can become a bottleneck for very long sequences, prompting research into more efficient attention mechanisms.\n\n\n\nModern LLM architectures, primarily based on decoder-only Transformers, also incorporate other layers such as Layer Normalization (LayerNorm) and activation functions like GeLU (Gaussian Error Linear Unit). While their precise theoretical underpinnings are still being researched, empirically, these components play a crucial role in stabilizing the training process and improving model performance.\n\n\n\n\nTraining a high-performing LLM is a multi-stage process, drawing upon principles from self-supervised learning, supervised learning, and reinforcement learning. The typical training pipeline involves:\n\n\nThis is the most computationally intensive stage, involving training the model on trillions of tokens of text data. The objective is self-supervised learning, where the model learns to predict masked words (for encoder models) or the next word in a sequence (for decoder models).\nData and Objective: Pretraining data is typically a diverse mix of text from the web, books, code repositories, and scientific articles. The data is often used “as is,” but increasingly, pretraining datasets are structured in a “task-response” format, similar to instruction tuning, to improve downstream task performance. The goal is to learn general language representations and a broad understanding of the world from this massive dataset.\nImportance: Pretraining equips the model with fundamental language capabilities and a vast amount of world knowledge, forming the foundation for subsequent fine-tuning stages.\n\n\n\nIn this stage, the pretrained model is further trained on a smaller dataset of millions of tokens with supervised learning. The focus shifts to aligning the model’s general language capabilities with the ability to follow instructions and perform specific tasks.\nData and Objective: Instruction tuning datasets consist of examples in a “instruction-response” format, covering a wide range of tasks like question answering, summarization, essay writing, code generation, and more. The data mixture is crucial. Training on a diverse and high-quality instruction dataset leads to models that generalize well across various tasks. A model heavily trained on code tasks, for example, might perform poorly on essay writing if not exposed to sufficient writing-related instructions.\nImportance: Instruction tuning teaches the model to understand and execute instructions, making it more useful for practical applications where users provide specific prompts or task descriptions.\n\n\n\nFor tasks where output quality is subjective or difficult to define objectively (e.g., essay quality, helpfulness of a chatbot response), Reinforcement Learning from Human Feedback (RLHF) is often employed.\nData and Objective: RLHF utilizes human preference data. Humans are presented with pairs of model-generated outputs for the same prompt and asked to choose the preferred output. This preference data is then used to train a reward model, which learns to predict human preferences. Subsequently, reinforcement learning algorithms (like Proximal Policy Optimization - PPO) are used to fine-tune the LLM to maximize the reward predicted by the reward model.\nImportance: RLHF helps align the model’s behavior with human values and preferences, improving the quality, helpfulness, and safety of generated text. It addresses subjective aspects of language quality that are difficult to capture with purely supervised learning objectives.\n\n\n\nSome advanced models, like OpenAI’s o1 or DeepSeek’s r1 reasoning models, incorporate additional reinforcement learning stages focused on improving reasoning abilities. While the exact details on how OpenAI trained their “o” series of models are hidden and proprietary, the speculation is that it could include test time search, process reward modeling, chain-of-thought based supervised finetuning, and more. DeepSeek’s r1-zero model does not use supervised finetuning at all and relies on verifable (or “rule-based”) rewards for training. Their r1 model, however, uses a combination of supervised finetuning, RLHF and verifiable rewards. The most fascinating thing about DeepSeek’s r1 model is reflection or backtracking, where the model can reflect on its own reasoning process and correct itself if it finds a mistake. According to the authors, this emerged during training and was not explicitly programmed into the model.\nData and Objective: The data for verifable rewards is mostly restricted to domains like math and code.\nImportance: Reinforcement finetuning for reasoning is a frontier in LLM training with multiple labs trying to understand how best to scale reasoning capabilities.\n\n\n\n\nDespite their impressive capabilities, LLMs have inherent limitations that are crucial to consider when designing applications.\n\n\nLLMs can exhibit prompt sensitivity. Slight variations in prompt phrasing, even while maintaining semantic meaning, can sometimes lead to surprisingly different model outputs. This stochastic nature, combined with the opacity of the training data, makes it challenging to predict model behavior consistently.\nImplications for Applications: Prompt sensitivity poses challenges for building reliable and predictable applications, especially in agentic systems where LLMs make decisions on behalf of users. Inconsistent outputs can undermine user trust and application stability.\nMitigation Strategies:\n\nPrompt Engineering Best Practices: Employing structured prompt formats, clear instructions, adding examples (few shot prompting), chain-of-thought, and consistent phrasing can improve prompt robustness.\nPrompt Testing and Selection: Systematically testing a range of prompts and selecting those that yield the most consistent and desired outputs for a given task. Many “observability” tools like wandb weave, arize phoenix, langsmith, and claude’s prompt tuner tools are available to help with this.\nEnsemble Methods: Combining outputs from multiple prompts or model instances can potentially reduce variance and improve robustness, but at a cost.\n\n\n\n\nLLMs can exhibit limited self-improvement. They may repeat the same mistakes or biases without fundamentally learning from their errors in an iterative manner. While models like OpenAI’s o1 and Claude 3.5 Sonnet demonstrate improved self-correction, particularly in code-related tasks, general self-improvement remains a significant challenge.\n\n\n\nLLMs primarily learn statistical correlations from massive datasets. While they can exhibit impressive “knowledge,” they often lack true “understanding” of underlying concepts and causal relationships.\nCounterfactual Reasoning Failures: When tested on counterfactual puzzles or questions that require reasoning about “what if” scenarios or understanding causal mechanisms, LLMs often perform poorly. This highlights their reliance on memorized patterns rather than genuine conceptual understanding. Some papers like “Reasoning or Reciting?” and “Planning in Strawberry Fields” emphasize distinguishing between knowledge (memory) and understanding through evaluations on counterfactual questions and plans.\n\n\n\nGeneral-purpose LLMs are trained on broad internet datasets. Many specialized domains, such as medicine, law, or specific technical fields, have their own extensive vocabularies, jargon, and conceptual frameworks that are not adequately represented in general language models.\nDomain-Specific Model Requirements: Effective application of LLMs in specialized domains often necessitates:\n\nDomain-Specific Fine-tuning: Further training general LLMs on domain-specific data to adapt their vocabulary and knowledge.\nSpecialized Models: Developing LLMs trained specifically for a particular domain from the outset.\nVocabulary Extension Techniques: Methods to expand the tokenizer vocabulary to include domain-specific terms.\nKnowledge Augmentation: Integrating LLMs with domain-specific knowledge bases or retrieval systems.\n\nConcepts and ideas that appear infrequently in the training data (the “long tail” of the knowledge distribution) are less likely to be learned effectively by LLMs. While Retrieval-Augmented Generation (RAG) can provide LLMs with relevant context from external knowledge sources, it is not a complete solution for long-tail knowledge. Generating high-quality text about rare or novel concepts may require more “core” knowledge and reasoning ability than the model possesses, even with retrieved context.\nChallenges for Niche Applications: Applications dealing with highly specialized or niche topics may encounter limitations due to the model’s lack of familiarity with long-tail concepts.\n\n\n\n\nThis introduction has provided a foundational understanding of Large Language Models. To further your exploration and begin applying LLMs in your projects, consider the following steps:\n\nExplore the Transformers Library: A powerful and user-friendly library for working with pre-trained LLMs in Python. Experiment with different models, tokenizers, and prompting techniques.\nDive into Prompt Engineering: A good rule of thumb is that your prompt should contain enough information to be useful for a human to understand. For code, I often think of the LLM as a junior developer that needs specific information on what to do next.\nPractice a lot: I personally have multiple subscriptions and use many LLMs through the API as well. For instance, I have found that DeepSeek-r1 is fantastic at code and math, even out-doing o1 and o3-mini in many cases, but for general physics questions, it is worse.\nTry Frameworks: langchain and other frameworks are relatively easy to explore, and some including langchain have a LLM-based chatbot for their docs that can generate starter code for you immediately. The only frustration I have is that their API changes every couple of months, so if you found a nice langchain tutorial from 6 months ago, it is unlikely to work anymore.\nStay up-to-date: Podcasts like thursdai and newsletters like AI News by smol-ai are great resources for staying up-to-date with the latest developments in LLMs."
  },
  {
    "objectID": "posts/2023-11-20-llms-summary/index.html#update-feb.-7th-2025",
    "href": "posts/2023-11-20-llms-summary/index.html#update-feb.-7th-2025",
    "title": "Large Language Models: A Compact Guide",
    "section": "",
    "text": "Best models and tools I use:\n\nCode: Claude 3.5 Sonnet, DeepSeek-r1 (see also DeekSeekv3 - 93.1% of aider’s own code writes are using Deepseekv3)\nWriting: Gemini 2.0 Pro Experimental 02-05 - this has become my default model for writing. The only complaint I have is that it currently supports file attachments through the AI studio interface, but not the Gemini app.\nSpeech-to-Speech: OpenAI’s GPT-4o, Gemini 2.0 Flash - both seem to have a 30 min limit unfortunately.\nReasoning/Planning: OpenAI-o1, DeepSeek-r1, Gemini Flash Thinking Experimental 01-21, OpenAI-o3-mini - in that order. I am hoping OpenAI-o3 will be considerably better than OpenAI-o1 and o3-mini when it becomes available to Plus users.\nResearch: NotebookLM, Gemini Deep Research. One major limitation of these tools and LLMs in general (except Claude 3.5 Sonnet apparently) is that they use OCR to convert PDFs into text, which often does not capture the layout and structure of the document.\nIDEs/Agents: windsurf, aider, github copilot - in that order. I also tried cursor, which is arguably the most popular IDE right now for power users. I personally do not find it’s composer to be better than Windsurf’s cascade. The tab might be better though. Also, Windsurf costs $10/month while Cursor $20/month with differences in how many times you can call “premium models” (GPT-4o, Claude 3.5 Sonnet, DeepSeek-r1, etc.). I will report back on how [OpenHands](https://github.com/All-Hands-AI/OpenHands) (previously called OpenDevin) compares to the other tools listed here.\n\n(For text-to-image, imagen-3 by Google and flux-dev are my top choices.)"
  },
  {
    "objectID": "posts/2023-11-20-llms-summary/index.html#key-components-of-modern-llm-architectures",
    "href": "posts/2023-11-20-llms-summary/index.html#key-components-of-modern-llm-architectures",
    "title": "Large Language Models: A Compact Guide",
    "section": "",
    "text": "At their core, Language Models are designed to learn the probability distribution of word sequences. I like to think of LLM architectures as composed of three major components:\n\nInput: This covers tokenization and embedding on input text. Tokenization is a bottleneck especially for domain-specific languages. Frontier research is exploring alternative tokenization methods and tokenization-free approaches that I will write more about later.\nCore (self-attention): Multi-head self-attention, several layers of it with residual connection forms the core of the transformer architecture (attention is all you need). This is arguably the reason why LLMs are so powerful at understanding multiple meanings of the same word, and doing “in-context learning”.\nOutput: While earlier models were only focusing on the “pretraining” phase that literally just does next-token prediction, newer models involve extensive instruction tuning and reinforecement learning based approaches to force the model to learn how to generate coherent text over long sequences. Some recent work like DeepSeekv3 has made improvements in the pretraining phase where they introduced an auxiliary multi-token prediction loss instead of just using a single token prediction loss that is commonplace.\n\nI plan to extend the following discussion with more about the recent innovations in each of the three components: context extension through Rotary Position Embeddings (RoPE), performance improvements through Flash Attention, multi-token prediction, etc.\n\n\nBefore text can be processed by an LLM, it must be converted into numerical representations. This is the role of the tokenizer. Tokenizers break down text into smaller units called tokens, which can be words, subwords, or characters. Different LLMs often employ distinct tokenization methods, leading to fragmentation in the ecosystem. For example, OpenAI models utilize Byte-Pair Encoding (BPE), while T5 uses SentencePiece.\nTokenization as a Potential Bottleneck: Tokenization can be a performance bottleneck and introduce limitations, particularly in these scenarios:\n\nOut-of-Vocabulary (OOV) Tokens: Tokenizers typically have a fixed vocabulary size. Words not present in this vocabulary are treated as OOV tokens, often represented by a special &lt;unk&gt; token. A high number of OOV tokens can degrade model performance as the model has no learned representation for these words.\nAdaptability to New Languages: Models trained primarily on English may struggle to tokenize languages with different scripts or linguistic structures (e.g., Chinese, Urdu, Swahili).\nDomain-Specific Languages: Technical domains like programming languages (HTML, Python) or specialized fields (medicine, law) pose challenges. These domains have unique syntax, terminology, and structures that general-purpose tokenizers may not handle optimally. Currently, as a side project, I am trying to port some old fluid dynamics codes from Fortran 90 to Python and finding that some LLMs are worse at understanding Fortran 90 (arguably out of favor in the industry).\n\n\n\n\nBroadly speaking, this is the stand-out feature of the neural network based approaches as opposed to classical Markovian or n-gram like models: you can embed anything (language, audio, video, images, etc.) into a numerical representation that captures its semantic meaning. The numerical tokens are then transformed into dense vector representations by a learned embedding layer. These embeddings are not just arbitrary numbers; they are designed to capture the semantic meaning of the tokens. Tokens with similar meanings are positioned closer together in the embedding space. The size of the embedding vector (embedding dimension) is a hyperparameter, with modern LLMs often employing sizes of 2048 or larger. The increasing the embedding dimension can significantly increase the model size and computational complexity.\nPurpose: Embeddings serve as a crucial bridge, translating discrete tokens into a continuous vector space where semantic relationships can be mathematically modeled. Pre-trained LLMs leverage embeddings learned from vast amounts of text data, enabling them to capture general language understanding.\n\n\n\nThe self-attention mechanism is arguably the most significant innovation driving the power of modern LLMs. It allows each token in a sequence to “attend” to all other tokens, enabling the model to capture contextual relationships within the input. This is in contrast to earlier sequential models (like RNNs) which processed text token by token.\nHow Self-Attention Works (Simplified): Imagine each token as having three vectors associated with it: a Query, a Key, and a Value. For each token, the model calculates an “attention score” by comparing its Query vector to the Key vectors of all other tokens in the sequence. These scores determine how much attention each token should pay to others when constructing its contextual representation. The Value vectors are then weighted by these attention scores and aggregated to produce the context-aware representation for each token.\nMultiple Attention Heads: Most LLMs utilize multi-head attention, meaning they perform the self-attention process multiple times in parallel with different sets of Query, Key, and Value matrices. This allows the model to learn diverse types of relationships and attend to different aspects of the input simultaneously, enriching the contextual understanding.\nComputational Considerations: It’s important to note that the computational complexity of self-attention is quadratic with respect to the sequence length (O(n2)), where n is the number of tokens. This can become a bottleneck for very long sequences, prompting research into more efficient attention mechanisms.\n\n\n\nModern LLM architectures, primarily based on decoder-only Transformers, also incorporate other layers such as Layer Normalization (LayerNorm) and activation functions like GeLU (Gaussian Error Linear Unit). While their precise theoretical underpinnings are still being researched, empirically, these components play a crucial role in stabilizing the training process and improving model performance."
  },
  {
    "objectID": "posts/2023-11-20-llms-summary/index.html#language-model-training-stages-from-raw-text-to-instruction-following",
    "href": "posts/2023-11-20-llms-summary/index.html#language-model-training-stages-from-raw-text-to-instruction-following",
    "title": "Large Language Models: A Compact Guide",
    "section": "",
    "text": "Training a high-performing LLM is a multi-stage process, drawing upon principles from self-supervised learning, supervised learning, and reinforcement learning. The typical training pipeline involves:\n\n\nThis is the most computationally intensive stage, involving training the model on trillions of tokens of text data. The objective is self-supervised learning, where the model learns to predict masked words (for encoder models) or the next word in a sequence (for decoder models).\nData and Objective: Pretraining data is typically a diverse mix of text from the web, books, code repositories, and scientific articles. The data is often used “as is,” but increasingly, pretraining datasets are structured in a “task-response” format, similar to instruction tuning, to improve downstream task performance. The goal is to learn general language representations and a broad understanding of the world from this massive dataset.\nImportance: Pretraining equips the model with fundamental language capabilities and a vast amount of world knowledge, forming the foundation for subsequent fine-tuning stages.\n\n\n\nIn this stage, the pretrained model is further trained on a smaller dataset of millions of tokens with supervised learning. The focus shifts to aligning the model’s general language capabilities with the ability to follow instructions and perform specific tasks.\nData and Objective: Instruction tuning datasets consist of examples in a “instruction-response” format, covering a wide range of tasks like question answering, summarization, essay writing, code generation, and more. The data mixture is crucial. Training on a diverse and high-quality instruction dataset leads to models that generalize well across various tasks. A model heavily trained on code tasks, for example, might perform poorly on essay writing if not exposed to sufficient writing-related instructions.\nImportance: Instruction tuning teaches the model to understand and execute instructions, making it more useful for practical applications where users provide specific prompts or task descriptions.\n\n\n\nFor tasks where output quality is subjective or difficult to define objectively (e.g., essay quality, helpfulness of a chatbot response), Reinforcement Learning from Human Feedback (RLHF) is often employed.\nData and Objective: RLHF utilizes human preference data. Humans are presented with pairs of model-generated outputs for the same prompt and asked to choose the preferred output. This preference data is then used to train a reward model, which learns to predict human preferences. Subsequently, reinforcement learning algorithms (like Proximal Policy Optimization - PPO) are used to fine-tune the LLM to maximize the reward predicted by the reward model.\nImportance: RLHF helps align the model’s behavior with human values and preferences, improving the quality, helpfulness, and safety of generated text. It addresses subjective aspects of language quality that are difficult to capture with purely supervised learning objectives.\n\n\n\nSome advanced models, like OpenAI’s o1 or DeepSeek’s r1 reasoning models, incorporate additional reinforcement learning stages focused on improving reasoning abilities. While the exact details on how OpenAI trained their “o” series of models are hidden and proprietary, the speculation is that it could include test time search, process reward modeling, chain-of-thought based supervised finetuning, and more. DeepSeek’s r1-zero model does not use supervised finetuning at all and relies on verifable (or “rule-based”) rewards for training. Their r1 model, however, uses a combination of supervised finetuning, RLHF and verifiable rewards. The most fascinating thing about DeepSeek’s r1 model is reflection or backtracking, where the model can reflect on its own reasoning process and correct itself if it finds a mistake. According to the authors, this emerged during training and was not explicitly programmed into the model.\nData and Objective: The data for verifable rewards is mostly restricted to domains like math and code.\nImportance: Reinforcement finetuning for reasoning is a frontier in LLM training with multiple labs trying to understand how best to scale reasoning capabilities."
  },
  {
    "objectID": "posts/2023-11-20-llms-summary/index.html#limitations-of-large-language-models-understanding-the-boundaries",
    "href": "posts/2023-11-20-llms-summary/index.html#limitations-of-large-language-models-understanding-the-boundaries",
    "title": "Large Language Models: A Compact Guide",
    "section": "",
    "text": "Despite their impressive capabilities, LLMs have inherent limitations that are crucial to consider when designing applications.\n\n\nLLMs can exhibit prompt sensitivity. Slight variations in prompt phrasing, even while maintaining semantic meaning, can sometimes lead to surprisingly different model outputs. This stochastic nature, combined with the opacity of the training data, makes it challenging to predict model behavior consistently.\nImplications for Applications: Prompt sensitivity poses challenges for building reliable and predictable applications, especially in agentic systems where LLMs make decisions on behalf of users. Inconsistent outputs can undermine user trust and application stability.\nMitigation Strategies:\n\nPrompt Engineering Best Practices: Employing structured prompt formats, clear instructions, adding examples (few shot prompting), chain-of-thought, and consistent phrasing can improve prompt robustness.\nPrompt Testing and Selection: Systematically testing a range of prompts and selecting those that yield the most consistent and desired outputs for a given task. Many “observability” tools like wandb weave, arize phoenix, langsmith, and claude’s prompt tuner tools are available to help with this.\nEnsemble Methods: Combining outputs from multiple prompts or model instances can potentially reduce variance and improve robustness, but at a cost.\n\n\n\n\nLLMs can exhibit limited self-improvement. They may repeat the same mistakes or biases without fundamentally learning from their errors in an iterative manner. While models like OpenAI’s o1 and Claude 3.5 Sonnet demonstrate improved self-correction, particularly in code-related tasks, general self-improvement remains a significant challenge.\n\n\n\nLLMs primarily learn statistical correlations from massive datasets. While they can exhibit impressive “knowledge,” they often lack true “understanding” of underlying concepts and causal relationships.\nCounterfactual Reasoning Failures: When tested on counterfactual puzzles or questions that require reasoning about “what if” scenarios or understanding causal mechanisms, LLMs often perform poorly. This highlights their reliance on memorized patterns rather than genuine conceptual understanding. Some papers like “Reasoning or Reciting?” and “Planning in Strawberry Fields” emphasize distinguishing between knowledge (memory) and understanding through evaluations on counterfactual questions and plans.\n\n\n\nGeneral-purpose LLMs are trained on broad internet datasets. Many specialized domains, such as medicine, law, or specific technical fields, have their own extensive vocabularies, jargon, and conceptual frameworks that are not adequately represented in general language models.\nDomain-Specific Model Requirements: Effective application of LLMs in specialized domains often necessitates:\n\nDomain-Specific Fine-tuning: Further training general LLMs on domain-specific data to adapt their vocabulary and knowledge.\nSpecialized Models: Developing LLMs trained specifically for a particular domain from the outset.\nVocabulary Extension Techniques: Methods to expand the tokenizer vocabulary to include domain-specific terms.\nKnowledge Augmentation: Integrating LLMs with domain-specific knowledge bases or retrieval systems.\n\nConcepts and ideas that appear infrequently in the training data (the “long tail” of the knowledge distribution) are less likely to be learned effectively by LLMs. While Retrieval-Augmented Generation (RAG) can provide LLMs with relevant context from external knowledge sources, it is not a complete solution for long-tail knowledge. Generating high-quality text about rare or novel concepts may require more “core” knowledge and reasoning ability than the model possesses, even with retrieved context.\nChallenges for Niche Applications: Applications dealing with highly specialized or niche topics may encounter limitations due to the model’s lack of familiarity with long-tail concepts."
  },
  {
    "objectID": "posts/2023-11-20-llms-summary/index.html#next-steps-and-getting-started",
    "href": "posts/2023-11-20-llms-summary/index.html#next-steps-and-getting-started",
    "title": "Large Language Models: A Compact Guide",
    "section": "",
    "text": "This introduction has provided a foundational understanding of Large Language Models. To further your exploration and begin applying LLMs in your projects, consider the following steps:\n\nExplore the Transformers Library: A powerful and user-friendly library for working with pre-trained LLMs in Python. Experiment with different models, tokenizers, and prompting techniques.\nDive into Prompt Engineering: A good rule of thumb is that your prompt should contain enough information to be useful for a human to understand. For code, I often think of the LLM as a junior developer that needs specific information on what to do next.\nPractice a lot: I personally have multiple subscriptions and use many LLMs through the API as well. For instance, I have found that DeepSeek-r1 is fantastic at code and math, even out-doing o1 and o3-mini in many cases, but for general physics questions, it is worse.\nTry Frameworks: langchain and other frameworks are relatively easy to explore, and some including langchain have a LLM-based chatbot for their docs that can generate starter code for you immediately. The only frustration I have is that their API changes every couple of months, so if you found a nice langchain tutorial from 6 months ago, it is unlikely to work anymore.\nStay up-to-date: Podcasts like thursdai and newsletters like AI News by smol-ai are great resources for staying up-to-date with the latest developments in LLMs."
  },
  {
    "objectID": "posts/2023-12-16-second-hand-fashion/index.html",
    "href": "posts/2023-12-16-second-hand-fashion/index.html",
    "title": "Automating second-hand fashion",
    "section": "",
    "text": "Note\n\n\n\nUpdate February 2025: For more detailed and up-to-date information, please visit fnauman.github.io/second-hand-fashion."
  },
  {
    "objectID": "posts/2023-12-16-second-hand-fashion/index.html#ai-in-the-fashion-industry",
    "href": "posts/2023-12-16-second-hand-fashion/index.html#ai-in-the-fashion-industry",
    "title": "Automating second-hand fashion",
    "section": "AI in the Fashion Industry",
    "text": "AI in the Fashion Industry\nAI has been used in many applications in the fashion industry including product recommendation, visual search, virtual try-on, and trend forecasting. Second-hand fashion, on the other hand, remains almost exclusively manual. The sorting and grading of second-hand clothing is a labor-intensive process that requires a lot of time and effort. The lack of automation in this sector is a major bottleneck in the transition to a circular economy.\nI am fortunate to be involved in two large projects aiming to automate the second-hand fashion industry. The first project is AI for Resource-Efficient Circular Fashion funded by the Swedish Innovation Agency, Vinnova. The second project is funded by the EU: Increasing Circularity and Sustainability in Textiles and Clothing in Europe."
  },
  {
    "objectID": "posts/2023-12-16-second-hand-fashion/index.html#sorting",
    "href": "posts/2023-12-16-second-hand-fashion/index.html#sorting",
    "title": "Automating second-hand fashion",
    "section": "Sorting",
    "text": "Sorting\nSorting is a multi-step process that involves the following steps:\n\nPre-sorting: Separate shoes, household textiles like bedsheets and curtains, and other non-fashion items from the fashion items.\nSorting fashion clothes [THIS PROJECT]: Predict various attributes of the clothing items and sort them for:\n\nReuse: Items that are in good condition and can be sold as-is. Reuse is the most sustainable option and has further sub-categories:\n\nSell in Sweden.\nSell outside Sweden or export.\n\nRepair: Items in need of repairs, but are otherwise reusable.\nRecycle: Items made of recyclable materials like 100% cotton.\nLandfill: Items that are in extremely poor condition and cannot be reused or recycled.\n\nFine sorting: This is the sorting that is most relevant to second-hand retailers that sell in-store and online. Their goal is to take the chunk of reusable clothing items and then decide which items to sell at what price and in what location. We do not address this in our project directly although our sorting model can be used to support this process.\n\nIn addition to this, clothes must be handled manually when they first arrive at the facility in large containers. Currently, no known technology exists that can fully automate this step although exciting advances in the field of robotics are being made."
  },
  {
    "objectID": "posts/2023-12-16-second-hand-fashion/index.html#ai-powered-sorting",
    "href": "posts/2023-12-16-second-hand-fashion/index.html#ai-powered-sorting",
    "title": "Automating second-hand fashion",
    "section": "AI-Powered Sorting",
    "text": "AI-Powered Sorting\nThe first major challenge that any project aiming to automate the second-hand fashion industry faces is the lack of data. Existing “foundation AI models” are largely biased towards first-hand fashion since that is the kind of data that is readily available on the internet. For instance, these models are incapable of recognizing the wear and tear of second-hand clothing since first-hand fashion images are usually of pristine quality.\nIn the Vinnova project that I am leading from RISE, we are developing a novel dataset with 30,000 used clothing items in partnership with Wargön Innovation. The first version of the dataset has already been released:\n\nDataset v1, 3000 clothing items: Zenodo link.\n\n\n\n\n\n\n\nImportant\n\n\n\nUpdate February 2025: v3 with 31,638 items was released on September 19th, 2024 here. For up to date information, please visit fnauman.github.io/second-hand-fashion.\n\n\nThe dataset has been released under a permissive CC-BY 4.0 license that allows commercial use given that the authors are properly cited.\nFurthermore, we are developing AI models to recognize damage on clothes and to grade them according to their quality. The scope of ongoing projects is not full automation, but to instead provide a “decision support tool”. A decision support tool is supposed to assist the human operator in making the final decision by judging the cloth condition, assessing the brand quality and how it compares with other brands in the market, and finally, estimating the best use case for the item."
  },
  {
    "objectID": "posts/2023-12-16-second-hand-fashion/index.html#challenges-and-opportunities",
    "href": "posts/2023-12-16-second-hand-fashion/index.html#challenges-and-opportunities",
    "title": "Automating second-hand fashion",
    "section": "Challenges and Opportunities",
    "text": "Challenges and Opportunities\nWe have identified the following challenges and opportunities in the second-hand fashion industry:\n\nData: While our dataset of 30,000 clothing items is the largest of its kind, it is still not large enough to train a deep learning model of the “foundation model” kind. Instead, we must resort to using existing foundation models and finetune them with this data. What makes this particularly challenging is that for first-hand fashion, training a model on, for example, pink T-shirts and black pants is sufficient, but for second-hand fashion, one must be able to distinguish between a pink T-shirt that is in good condition and one that is in poor condition. In other words, we need a dataset large enough to contain different degrees of damage to clothes. One major problem with lack of data will be addressed by the introduction of the digital product passport that aims to preserve the data about a product throughout its life cycle.\nAnnotations: Similar to the subjectivity of language annotations, the annotations of second-hand clothing items are often specific to the annotators and the scope of the facility they are working for. For instance, Wargön Innovation works with the Swedish Red Cross and does not directly price the clothing items. In contrast, other sorting facilities like Myrorna and Björkåfrihet price the items to be sold in their own stores. This means that the annotations are not only subjective, but also specific to the business model of the sorting facility.\nRobotics: The second-hand fashion industry is still almost exclusively manual. With the recent advances in robotics, there is an exciting opportunity to fully automate the entire sorting process from the pre-sorting step to the fine sorting step."
  },
  {
    "objectID": "posts/2023-12-16-second-hand-fashion/index.html#conclusion",
    "href": "posts/2023-12-16-second-hand-fashion/index.html#conclusion",
    "title": "Automating second-hand fashion",
    "section": "Conclusion",
    "text": "Conclusion\nThe second-hand fashion industry is ripe for disruption. With the increase in global awareness about the environmental impact of the textile industry, the second-hand fashion retail is expected to grow exponentially. Nonetheless, the industry is still largely manual and lacks large scale datasets and AI models. The introduction of the digital product passport and extended producer responsibility are likely to accelerate the automation of the second-hand fashion industry. Most players in this sector are volunteer run small businesses that lack the resources to invest in AI and robotics. With project like ours, we hope to make the technology accessible to all players."
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "CV: Farrukh Nauman",
    "section": "",
    "text": "(+46) 0702984959 | Email | LinkedIn | Github | Homepage | PDF"
  },
  {
    "objectID": "cv.html#value-proposition",
    "href": "cv.html#value-proposition",
    "title": "CV: Farrukh Nauman",
    "section": "VALUE PROPOSITION",
    "text": "VALUE PROPOSITION\nAI consultant specializing in Gen AI, LLMs, and Computer Vision, translating complex AI capabilities into tangible business value. Proven ability to deliver significant operational improvements:\n\n40% reduction in manual inspection costs for textile quality assessment.\n50%+ reduction in data collection costs through synthetic data generation.\n90% lower hardware costs for industrial IoT implementations."
  },
  {
    "objectID": "cv.html#consulting-offers",
    "href": "cv.html#consulting-offers",
    "title": "CV: Farrukh Nauman",
    "section": "CONSULTING OFFERS",
    "text": "CONSULTING OFFERS\n\nProof-of-Concept (Fixed Price/4-weeks) - dataset audit, model prototype, ROI roadmap.\nHourly/Daily Rate Projects - flexible engagement for ongoing development and implementation.\nFractional AI Lead (Retainer) - steer data teams, drive AI initiatives, governance (1-2 days/week).\nAI Workshops - hands-on training in generative AI, vision and LLMs."
  },
  {
    "objectID": "cv.html#skills-tech-stack",
    "href": "cv.html#skills-tech-stack",
    "title": "CV: Farrukh Nauman",
    "section": "SKILLS & TECH STACK",
    "text": "SKILLS & TECH STACK\n\n\n\n\n\n\n\nArea\nSkills\n\n\n\n\nAI & ML\nLLMs: OpenAI, Gemini, HF Transformers, RAG, Fine-tuning, Synthetic Data, OCR, Vector DBs;GenAI, Vision: Text-to-Image, Inpainting, Object Detection, Classification, Segmentation, Edge AI;Core ML: Predictive Modeling, Anomaly Detection, Time Series;Libs/Frameworks: PyTorch (Expert, 6 yrs), Transformers, Diffusers, LangChain, Weights & Biases\n\n\nMLOps & Cloud\nAzure ML, Docker, CI/CD, Model Monitoring/Serving, Experiment Tracking, Git, REST APIs\n\n\nProgramming\nPython (Expert, 8+ yrs), C/C++ (Proficient, 8 yrs), SQL, High Performance Computing (8 years)\n\n\nBusiness\nStakeholder Management, Requirements Gathering, Project Scoping, Solution Architecture, Technical Leadership, ROI Analysis, Client Communication\n\n\nLanguages\nEnglish (Fluent), Swedish (SFI C2), Urdu (Native)"
  },
  {
    "objectID": "cv.html#experience",
    "href": "cv.html#experience",
    "title": "CV: Farrukh Nauman",
    "section": "EXPERIENCE",
    "text": "EXPERIENCE\n\nRISE Research Institutes of Sweden AB\nAI Researcher & Consultant\nJul 2021 - Present | Linköping, Sweden\nProject Lead: Sustainable Fashion AI Automation (2022-2025: 24 months): Leading two major initiatives in sustainable fashion: Vinnova: AI for Circular Fashion (Project Lead, ~9M SEK) and CISUTAC (AI Lead, ~2M SEK).\n\nChallenge: Manual quality inspection created major bottlenecks in circular fashion supply chain, with 30% inconsistency in assessments and excessive labor costs driving up prices by 25%.\nSolution: Designed and implemented end-to-end computer vision system for automated attribute detection.\nApproach:\n\nData: Custom annotation & collection setup; Cleaning, enrichment.\nModel: Training & optimization; Synthetic data generation.\nDeployment: Pilot deployment and validation.\n\nImpact: 40% reduction in processing time, 50%+ reduction in data collection costs through synthetic data.\nTechnologies: PyTorch, Vision Transformers, CLIP, Gradio, Docker, Flask, Synthetic Data Generation, Inpainting.\nRecognition: 1 of only 5 projects presented at EU sustainable AI (2023) and Vinnova Innovation week (2022).\nDeliverables: Pilot-ready AI system, Annotated public dataset, Roadmap for industry adoption.\n\nProject: LLM Implementation for Regional Textile Recycling Network (2024-2025: 4 months):\n\nChallenge: Clients needed to integrate LLMs into their networking platform for textile recycling in Europe.\nSolution: Designed a custom LLM chatbot and retrieval system for both structured and unstructured data.\nImpact: Enabled a smart search and retrieval system for connecting textile actors in Europe.\nTechnologies: Retrieval Augmented Generation, LangChain, Evaluations, Prompt Engineering, Synthetic Data.\n\nProject: Low Energy IoT Solutions for Industrial Clients (2022: 4 months):\n\nChallenge: Clients needed to process sensor data at the edge with limited energy, preventing real-time analysis.\nSolution: Identified energy-efficient AI algorithms (miniROCKET algorithm) for edge devices that is faster than deep learning methods by over 2000x.\nImpact: Enabled real-time sensor data analysis with 90% lower hardware costs.\nTechnologies: Edge AI, Time Series Classification, Anomaly Detection, Low-Energy Computing.\n\nAI Mentorship Program (2023-2024): Established and led mentorship program for Master’s thesis students in AI, resulting in 4 industry-applicable projects.\n\nProjects: Damage Detection in Fashion, Generative AI for Fashion, Time Series Forecasting for Fashion Trends, Image Embeddings for Second-Hand Fashion.\nActivities: Provided hands-on training in deep learning and AI for advanced industrial AI application.\n\nOther Projects:\n\nAero EDIH (2024): Consulted with startups on data/model strategies for on-device drone deployment for vehicle/person detection and runway debris identification. Tasks: Object Detection, Edge AI, Diffusion Models.\nRamverk (2024): Prepared roadmap for air traffic control automation, including reinforcement learning state-of-the-art models and data collection proposal. Tasks: Reinforcement Learning, Data Collection.\nGreenerFlow (2023): Factor analysis for traffic congestion in metropolitan areas, led consortium formation for a larger project. Tasks: Time Series Analysis, Multi-modal Data.\nSHOW - Hard Brake Detection (2022): Developed time series anomaly detection models to identify hard brakes in autonomous buses. Tasks: Time Series Classification, Anomaly Detection.\n\n\n\n2MNordic IT Consulting AB\nData Scientist & Data Engineer\nDec 2019 - Jun 2021 | Gothenburg, Sweden\nProject: Early Warning System for Student Performance (2020: 6 months):\n\nChallenge: Helsingborg school district lacked ability to identify at-risk students early, resulting in up to 40% failure rate in some schools in 9th grade.\nSolution: Developed predictive analytics system identifying absence, poor grades in English and Math as the key indicators in 6th grade that predict 9th grade performance, with school-level feature analysis for targeted funding.\nImpact: Enabled early intervention for 10% of the student population, and provided data-driven policy recommendations impacting 3,000+ students.\nTechnologies: Azure DevOps, Azure Functions, Data Factory, Python, SQL, Power BI.\n\nProject: Mathematics Assessment Optimization (2021: 4 months):\n\nChallenge: New digital mathematics test showed inconsistencies with traditional grading schemes, causing confusion and potential inequities.\nSolution: Conducted comprehensive data analysis of test results across 8 schools, identifying specific misalignments between grading schemes.\nImpact: Findings led to significant improvement in assessment accuracy and informed critical education policy adjustments affecting district-wide mathematics curriculum.\nTechnologies: Scikit-learn, Statistical Analysis, Python, Data Visualization, Azure Notebooks.\n\n\n\nPrevious Research Positions\n2009–2019\n\nResearch Fellow, Chalmers University of Technology: Gothenburg, Sweden (2018–2019) Complex systems modeling, large-scale data analysis\nResearch Scientist, Niels Bohr Institute: Copenhagen, Denmark (2015–2018) Simulation, forecasting, computational modeling\nResearch Assistant/PhD Student, Univ. of Rochester: New York, USA (2009–2015) Data analysis, predictive modeling"
  },
  {
    "objectID": "cv.html#education-certifications",
    "href": "cv.html#education-certifications",
    "title": "CV: Farrukh Nauman",
    "section": "EDUCATION & CERTIFICATIONS",
    "text": "EDUCATION & CERTIFICATIONS\n\nMicrosoft Certified\nAzure Data Engineer Certificate\n2020\n\n\nUniversity of Rochester\nPhD in Physics and Astronomy\nOct 2015 | Rochester, New York (USA)\nFocus: Complex Systems Modeling, Data Analysis, Computational Fluid Dynamics, High Performance Computing, C/C++"
  },
  {
    "objectID": "cv.html#awards-achievements",
    "href": "cv.html#awards-achievements",
    "title": "CV: Farrukh Nauman",
    "section": "AWARDS & ACHIEVEMENTS",
    "text": "AWARDS & ACHIEVEMENTS\n\nHorton fellowship from Laboratory for Laser Energetics - full research funding award. 2010-2015\nSusumu Okubo Prize for highest performance on graduate comprehensive exam and excellence in coursework. 2011"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Farrukh Nauman",
    "section": "",
    "text": "I help organizations leverage cutting-edge AI for measurable business impact. As an AI Solutions Consultant specializing in Large Language Models (LLMs), Generative AI, and Computer Vision, I deliver custom solutions that translate business needs into scalable AI architectures. My expertise includes:\n\n🤖 LLMs & Generative AI: Custom LLM and generative AI systems for synthetic data generation and smart assistants.\n🔍 Computer Vision: Design and deployment of computer vision systems for automated process optimization and inspection.\n📊 Retrieval Augmented Generation (RAG): Smart knowledge management and document QA using cutting-edge RAG systems.\n💼 AI Strategy & Technical Advisory: Strategic guidance from feasibility to deployment with a focus on ROI and implementation.\n\nWith a proven track record in developing end-to-end computer vision systems, synthetic data frameworks, and custom LLM solutions, I help businesses overcome technical challenges and achieve significant efficiency gains.\n\n\n\n\n\n\n🤝 Available for Consulting\n\n\n\n\n\n\n\n\n\n\nEmail me\n\n\n\n\n\n\n\n\nMLOps, Object Detection, Synthetic Data, Web App Development, Image Classification, Project Management\n\n\n\nDeveloping custom LLM solutions for automated research report generation and analysis.\n\n\n\nComputer vision systems for farming applications.\n\n\nView full consulting →\n\n\n\n\n\n\n\nInference on HuggingFace - February 05, 2025\nFrom Python to React: Using Claude Artifacts and ChatGPT Canvas to Build Apps - January 26, 2025\nUploading datasets to Hugging Face - January 26, 2025\nIntelligence as a Complex System: Lessons from Physics - June 15, 2024\nAutomating second-hand fashion - December 16, 2023\nLarge Language Models: A Compact Guide - November 20, 2023\n\nView all posts →"
  },
  {
    "objectID": "index.html#consulting",
    "href": "index.html#consulting",
    "title": "Farrukh Nauman",
    "section": "",
    "text": "MLOps, Object Detection, Synthetic Data, Web App Development, Image Classification, Project Management\n\n\n\nDeveloping custom LLM solutions for automated research report generation and analysis.\n\n\n\nComputer vision systems for farming applications.\n\n\nView full consulting →"
  },
  {
    "objectID": "index.html#recent-updates",
    "href": "index.html#recent-updates",
    "title": "Farrukh Nauman",
    "section": "",
    "text": "Inference on HuggingFace - February 05, 2025\nFrom Python to React: Using Claude Artifacts and ChatGPT Canvas to Build Apps - January 26, 2025\nUploading datasets to Hugging Face - January 26, 2025\nIntelligence as a Complex System: Lessons from Physics - June 15, 2024\nAutomating second-hand fashion - December 16, 2023\nLarge Language Models: A Compact Guide - November 20, 2023\n\nView all posts →"
  },
  {
    "objectID": "randomposts/2025-01-31-hf-data-upload/index.html",
    "href": "randomposts/2025-01-31-hf-data-upload/index.html",
    "title": "Uploading datasets to Hugging Face",
    "section": "",
    "text": "Uploading datasets to huggingface turned out to be harder than I initially thought."
  },
  {
    "objectID": "randomposts/2025-01-31-hf-data-upload/index.html#data-formatting",
    "href": "randomposts/2025-01-31-hf-data-upload/index.html#data-formatting",
    "title": "Uploading datasets to Hugging Face",
    "section": "Data formatting",
    "text": "Data formatting\nTo be able to view the dataset in the Hugging Face Datasets Hub, the dataset needs to be formatted in the right way. I had an image classification dataset with several target attributes. I followed the guide here. Here is how I formatted the dataset:\n./\n├── train\n│   ├── metadata.csv\n│   ├── front_2024_02_29_14_26_45.jpg\n│   ├── ...\n├── test\n│   ├── metadata.csv\n│   ├── front_2024_05_30_12_30_02.jpg\n│   ├── ...\nwhere the metadata.csv file contains the file_name as the first column and several other columns each corresponding to a target attribute. Here is a sample:\nfile_name,brand,usage,condition,type,category,price,trend,colors,cut,pattern,season,text,pilling,damage,stains,holes,smell,material\nfront_2022_12_14_08_48_42.jpg,Junkyard,Export,3,Jeans,Ladies,50-100,Denim,['Blue'],['Loose'],None,Spring,,4,,Minor,None,None,100%cotton\nfront_2023_06_29_08_22_48.jpg,Stacy,Reuse,4,Jeans,Unisex,50-100,None,['Brown'],['Tight'],None,All,,3,,None,None,None,\"98% cotton, 2% elastane\"\nWhen rendered in the dataset viewer in the Hugging Face Datasets Hub, the dataset converts the file_name to an image preview with the title image and retains the other columns. Here is the preview of the dataset:"
  },
  {
    "objectID": "randomposts/2025-01-31-hf-data-upload/index.html#what-worked",
    "href": "randomposts/2025-01-31-hf-data-upload/index.html#what-worked",
    "title": "Uploading datasets to Hugging Face",
    "section": "What worked",
    "text": "What worked\nIn the same image_dataset tutorial, they describe how to upload the dataset using the python command:\n\n\n\n\n\n\nImportant\n\n\n\nload_dataset name is misleading: it is not loading the dataset, but it is really setting up your dataset locally in a format suitable for the data viewer in the Hugging Face Datasets Hub. It should really be called setup_dataset.\n\n\nfrom datasets import load_dataset\n\n# Load the LOCAL folder as a `huggingface/datasets` dataset\ndataset = load_dataset(\"imagefolder\", data_dir=\"./\") # `imagefolder` is a special dataset type that loads images\n\n# Upload the dataset to Hugging Face\ndataset.push_to_hub(\"fnauman/fashion-second-hand-front-only\", private=True) # `private=True` makes the dataset repo private\nI recommend first uploading the dataset as a private dataset to ensure the upload worked and the data preview works as expected. You can later make the dataset public if you wish."
  },
  {
    "objectID": "randomposts/2025-01-31-hf-data-upload/index.html#what-did-not-work",
    "href": "randomposts/2025-01-31-hf-data-upload/index.html#what-did-not-work",
    "title": "Uploading datasets to Hugging Face",
    "section": "What did not work",
    "text": "What did not work\nFollowing the instructions here, I tried using the huggingface-cli command with two variations, but it did not work.\nhuggingface-cli upload fashion-second-hand-front-only . . --repo-type dataset\nhuggingface-cli upload-large-folder fashion-second-hand-front-only --repo-type dataset . --num-workers=8\nBoth of these commands crashed and were relatively slow. I suspect it has to do with the large number of files (30,000) in the dataset."
  },
  {
    "objectID": "randomposts/2025-01-26-react-template/index.html",
    "href": "randomposts/2025-01-26-react-template/index.html",
    "title": "From Python to React: Using Claude Artifacts and ChatGPT Canvas to Build Apps",
    "section": "",
    "text": "As a seasoned Python developer, I’m used to the comfort of conda environments and the predictability of pip. But lately, I’ve been diving headfirst into the wild world of web development with React. What prompted this shift? The incredible advancements in AI tools like Claude’s new artifact feature and ChatGPT’s enhanced support for rendering HTML and React. These tools have made it ridiculously easy to generate React UIs with simple natural language prompts.\nHowever, bridging the gap between AI-generated code and a functional, maintainable application required me to master a new set of tools and concepts. The most pressing challenge? Taming the JavaScript ecosystem. This blog post chronicles my journey, focusing on setting up a solid React template using Vite while navigating the intricacies of Node.js and its package managers.\n\ncreate-react-app does not work; vite does\nMy first instinct was to reach for the familiar create-react-app. Unfortunately, as of January 2025, there are significant issues (see this GitHub issue and many others).\nVite (French for “fast”) is a next-generation build tool that significantly improves the front-end development experience. Here’s how I set up my React template using Vite:\n\nPrerequisites:\nThis guide assumes a Linux-based system (specifically Ubuntu 24.04 LTS in my case). I’ll update my experiences with Windows later.\n\n\nStep 1: Node.js and the Power of nvm\nBefore diving into Vite, we need Node.js, the runtime environment that allows us to run JavaScript outside of a browser. However, different projects might require different Node.js versions. Here’s where Node Version Manager (nvm) comes to the rescue.\n\nInstalling nvm: bash     curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.40.1/install.sh | bash\nInstalling Node.js (LTS): bash     nvm install --lts\n\nnvm allows you to seamlessly switch between Node.js versions using a simple .nvmrc file in your project root, ensuring compatibility across your projects.\n\n\nStep 2: Initializing the React Template with Vite\nWith Node.js in place, creating a React template is a breeze:\nnpm create vite@latest my-react-app\nThis command prompts you to choose a framework (React, Vue, Svelte, etc.) and whether to use JavaScript or TypeScript. I opted for React and JavaScript. You can also use the shorthand: npm create vite@latest my-react-app -- --template react.\n\n\nStep 3: Understanding npm vs. npx\nThroughout this process, you’ll encounter both npm and npx. Here’s a simple way to distinguish them:\n\nnpm (Node Package Manager): Use it to install packages, either globally or locally within a project.\nnpx (Node Package Execute): Use it to run packages, often one-off tools or generators, without installing them permanently.\n\nFor example, we used npm create vite@latest to initialize our project because create-vite is a tool we might use again. However, for tasks like adding a shadcn component later, we’ll use npx.\n\n\nStep 4: Environment isolation - node_modules Directory\nUnlike Python’s virtual environments, Node.js relies on a project-specific node_modules directory to store dependencies. This directory can become quite large, but it guarantees that each project has its own isolated set of packages.\nKey Takeaway: Never share node_modules between projects. Always run npm install in a new project clone to populate the node_modules directory based on the package.json and package-lock.json files.\n\n\nStep 5: Embracing tailwindcss and shadcn (with a Caveat)\nModern React development often involves styling libraries like tailwindcss and component libraries like shadcn.\nImportant Note: shadcn is not an npm package but rather a collection of components that you can add to your project. It relies on Radix UI (@radix-ui/react-*) packages for its core functionality.\nIntegrating tailwindcss and shadcn can be tricky due to version conflicts. As of my writing, tailwindcss recently released a major version 4, and shadcn’s documentation hasn’t fully caught up.\nMy Solution: I’ve created a public template repository that successfully integrates tailwindcss version 3.4.17 with shadcn. It includes all the necessary configuration changes to the Vite template.\n\n\nStep 6: Organizing Your Code with Components\nFor larger projects, it’s crucial to structure your code effectively. Instead of dumping everything into src/App.tsx, create a src/components directory for your UI components. You can then import these components into App.tsx. Most LLMs seem to bundle everything in a single App.tsx by default, but you can prompt them to write modular code by separating out the components.\nHere’s a suggested folder structure:\nmy-react-app/\n├── node_modules/\n├── public/\n├── src/\n│   ├── components/\n│   │   └── Interface.tsx # Main UI code\n│   ├── App.css\n│   ├── App.tsx         # Import and use your UI components\n│   ├── index.css\n│   ├── main.tsx\n│   └── vite-env.d.ts\n├── index.html\n├── package.json\n├── package-lock.json\n├── tsconfig.json / jsconfig.json\n├── tsconfig.node.json\n└── vite.config.ts / vite.config.js\n\n\nStep 7: Running Your App\nFinally, to see your app in action, use:\nnpm run dev\nThis starts the Vite development server, typically at localhost:5173 (unlike create-react-app’s default localhost:3000).\n\n\n\nConclusion: JavaScript Environment Isolation is Great\nThe JavaScript ecosystem can feel daunting at first, especially coming from a Python background. However, with tools like Vite and a clear understanding of Node.js’s package management, setting up a modern React development environment becomes manageable.\nMy template repository provides a solid starting point, and I encourage you to explore it, adapt it, and contribute to it. As I continue my journey into web development, I’ll keep updating this blog with new insights and discoveries. Stay tuned! Github repository link: https://github.com/fnauman/clip_react\nI hope this comprehensive blog post is helpful! Let me know if you’d like any adjustments or further details on specific aspects."
  },
  {
    "objectID": "randomposts/2025-02-05-hf-inference/index.html",
    "href": "randomposts/2025-02-05-hf-inference/index.html",
    "title": "Inference on HuggingFace",
    "section": "",
    "text": "HuggingFace just announced that they now support third party inference providers: fal, Replicate, Sambanova, Together AI both directly through the HuggingFace Hub and their SDKs.\nBeing a Pro user of HuggingFace, I get $2 of credits to use each month. So I played around with the Flux model:\nfrom huggingface_hub import InferenceClient\n\nclient = InferenceClient(provider=\"fal-ai\", token=\"hf_***\") # Enable serverless inference when creating the token\n\nimage = client.text_to_image(\"Close-up of a cheetah's face, direct frontal view. Sharp focus on eye and skin texture and color. Natural lighting to capture authentic eye shine and depth.\", model=\"black-forest-labs/FLUX.1-schnell\") \n\nimage.save(\"cheetah.png\")\nThe output looks like this:\n\nThis is fantastic! I can now run quick experiments with many different models on the huggingface hub. There is a text box on the HuggingFace Hub where I can enter text and start generating images (or text for a LLM) easily:\n\nI can even get the code to run this via their Python SDK:\nfrom huggingface_hub import InferenceClient\n\nclient = InferenceClient(\n    provider=\"fal-ai\",\n    api_key=\"hf_xxxxxxxxxxxxxxxxxxxxxxxx\"\n)\n\n# output is a PIL.Image object\nimage = client.text_to_image(\n    \"Astronaut riding a horse\",\n    model=\"black-forest-labs/FLUX.1-dev\"\n)\nThe only challenge I found so far is that fal-ai for example does support the Flux 1.1 pro through their API, but since that model is not available on the HuggingFace Hub, I can’t use it. I get a ValueError: Model fal-ai/flux-pro/v1 is not supported with FalAI for task text-to-image. error when I try to use it."
  },
  {
    "objectID": "consulting.html",
    "href": "consulting.html",
    "title": "Consulting",
    "section": "",
    "text": "Below you’ll find a selection of projects that showcase my expertise in Generative AI, LLMs, Computer Vision, and AI strategy. Each project demonstrates how I’ve helped organizations translate business needs into scalable AI architectures with measurable impact.\n\n\n\n\n\n\nSpecialized AI Consulting Services\n\n\n\n\nGenerative AI & LLMs: Custom solutions for synthetic data generation and smart assistants.\nComputer Vision: Automated process verification systems that reduce manual inspection costs.\nRetrieval Augmented Generation (RAG): Smart knowledge management and document QA systems.\nAI Strategy & Technical Advisory: Guidance from feasibility assessment to deployment.\n\nSchedule a consultation Email me"
  },
  {
    "objectID": "consulting.html#ai-solutions-for-your-business-challenges",
    "href": "consulting.html#ai-solutions-for-your-business-challenges",
    "title": "Consulting",
    "section": "",
    "text": "Below you’ll find a selection of projects that showcase my expertise in Generative AI, LLMs, Computer Vision, and AI strategy. Each project demonstrates how I’ve helped organizations translate business needs into scalable AI architectures with measurable impact.\n\n\n\n\n\n\nSpecialized AI Consulting Services\n\n\n\n\nGenerative AI & LLMs: Custom solutions for synthetic data generation and smart assistants.\nComputer Vision: Automated process verification systems that reduce manual inspection costs.\nRetrieval Augmented Generation (RAG): Smart knowledge management and document QA systems.\nAI Strategy & Technical Advisory: Guidance from feasibility assessment to deployment.\n\nSchedule a consultation Email me"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog & Technical Notes",
    "section": "",
    "text": "short-note category represents random thoughts and things I’ve learned. The rest of the posts are longer-form posts.\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\n\nInference on HuggingFace\n\n2 min\n\n\nshort-note\n\nhuggingface\n\ninference\n\ntext-to-image\n\nflux\n\n\n\nPlaying with the Inference Providers on HuggingFace\n\n\n\nFarrukh Nauman\n\n\nFeb 5, 2025\n\n\n\n\n\n\n\n\n\n\n\nFrom Python to React: Using Claude Artifacts and ChatGPT Canvas to Build Apps\n\n5 min\n\n\nshort-note\n\nwebapps\n\nreact\n\n\n\nLearn how to set up a modern web development environment: React, Node.js, and Vite.\n\n\n\nFarrukh Nauman\n\n\nJan 26, 2025\n\n\n\n\n\n\n\n\n\n\n\nUploading datasets to Hugging Face\n\n2 min\n\n\nshort-note\n\nhuggingface\n\ndatasets\n\n\n\nHugging Face Datasets\n\n\n\nFarrukh Nauman\n\n\nJan 26, 2025\n\n\n\n\n\n\n\n\n\n\n\nIntelligence as a Complex System: Lessons from Physics\n\n5 min\n\n\nArtificial Intelligence\n\nComplex Systems\n\nNatural Language Processing\n\nLarge Language Models\n\n\n\nUnderstanding Intelligence Through the Lens of Physics\n\n\n\nFarrukh Nauman\n\n\nJun 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutomating second-hand fashion\n\n6 min\n\n\nArtificial Intelligence\n\nSustainable Fashion\n\n\n\nHow can AI be used to accelerate the transition to a circular economy?\n\n\n\nFarrukh Nauman\n\n\nDec 16, 2023\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models: A Compact Guide\n\n15 min\n\n\nArtificial Intelligence\n\nNatural Language Processing\n\nLarge Language Models\n\n\n\nWhat are Large Language Models? What are their limitations and common use cases?\n\n\n\nFarrukh Nauman\n\n\nNov 20, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-06-15-intelligence-complex/index.html",
    "href": "posts/2024-06-15-intelligence-complex/index.html",
    "title": "Intelligence as a Complex System: Lessons from Physics",
    "section": "",
    "text": "In the rapidly evolving field of artificial intelligence, there’s a growing need to understand the nuances and complexities of intelligence itself. By drawing analogies from successful physical models of complex systems, we can gain valuable insights into the nature of intelligence and the challenges we face in replicating it. This essay explores the parallels between intelligence and other complex phenomena in physics, highlighting why simplistic approaches to AI may fall short of true artificial general intelligence (AGI).\n\n\n\nJust as physical phenomena exhibit varying degrees of complexity, intelligence exists on a spectrum. Consider the following examples:\n\nTurbulence in fluid dynamics:\n\nSimple: Rayleigh–Bénard convection near the transition point.\nComplex: Plasma behavior around supermassive black holes (Reynolds number \\(\\sim 10^{20}\\)).\n\nIntelligence tasks:\n\nSimple: Grade school math problems.\nComplex: Developing groundbreaking scientific theories (e.g., the Ising model in ferromagnetism).\n\n\nThis spectrum illustrates that, like turbulence, we may not yet know if there’s an upper limit to intelligence. It also suggests that for many tasks, a simplified or “compressed” representation might suffice, explaining why some believe AGI has been achieved based on performance in limited domains. The complexity of turbulence is well characterized by the Reynolds number, but studies in the scaling laws of LLMs leaves a lot to be desired where claims of emergence are being made on simple datasets with fixed task complexity, input and output lengths. See Are Emergent Abilities of Large Language Models a Mirage? for a refreshing take on this.\n\n\n\nHistorically, scientists have fallen into the trap of reductionism – the belief that complex phenomena can be fully explained by understanding their fundamental components. Paul Dirac’s 1929 statement exemplifies this:\n\n“The underlying physical laws necessary for the mathematical theory of a large part of physics and the whole of chemistry are thus completely known.” Source\n\nHowever, just as a unified theory of fundamental forces wouldn’t explain emergent phenomena in physics, a single AI model is unlikely to capture the full spectrum of intelligence. This reductionist thinking can lead to overestimating the capabilities of current AI models, which excel in specific tasks but struggle with generalization and complex reasoning.\n\n\n\n\nDynamic nature: Intelligence is inherently non-equilibrium, dynamic, nonlinear, and high-dimensional. A static language model, no matter how advanced, cannot fully capture these aspects.\nHierarchical complexity: Like physical systems, intelligence requires flexible frameworks that allow for hierarchical representations. In physics, we have:\n\nN-particle descriptions (e.g., molecular dynamics)\nKinetic descriptions (e.g., Boltzmann, Vlasov equations)\nFluid descriptions (e.g., Navier-Stokes equations)\nMean field descriptions (e.g., filtered turbulent fields)\n\nAI research needs analogous frameworks to capture different levels of cognitive processes. However, one might argue that just like how one can use synthetic turbulence models through stochastic forcing to good effect for modeling unobserved physics across scales, GPT-like models with an analogus stochastic training process might be able to capture higher-level cognitive processes.\nMeta-frameworks for problem-solving: Current AI models lack robust strategies for approaching intractable problems. For instance, when experimental data is scarce or the physical system under consideration is extremely complex, breakthroughs in physics often came from constructing simplified models that capture the essence of complex phenomena (e.g., the Ising model for ferromagnetism).\nData limitations: Current AI models have almost no inductive biases and learn everything from the data, which has limitations:\n\nWeb-scale data has complex reasoning tasks only in their long-tail, which makes complex reasoning difficult to learn.\nDetailed reasoning steps are not available since humans only write down the final answer.\nEqual weighting of data samples is sub-optimal since only a fraction represent high-quality research and content.\nExamples from long-term scientific development are randomly distributed in the data and not systematically organized (e.g., the evolution of theories over decades).\n\nThe specific case of equal weighting of data is particularly problematic since many articles and books are written by people without adequate expertise and contain arguments without rigorous theoretical calculations and experimental results.\n\n\n\n\nDespite these challenges, AI research progresses at an unprecedented rate compared to other complex fields thanks to:\n\nImmediate access to state-of-the-art models through APIs and open-source libraries.\nEnhanced tooling for data ingestion and generation.\nThe ability to build upon existing work rapidly.\n\nContrast this with research in turbulence or computational fluid dynamics, where reproducing results can take years because of:\n\nComplex, million-line codebases in C, C++, Fortran.\nLimited access to high-performance computing.\nLack of open data sharing practices, and detailed model descriptions for reproducibility.\n\nAs an example, consider the difficulty in generating \\(1000\\) time steps for a turbulent flow simulation and contrast it with generating \\(1000\\) tokens in language models through the interface, API or locally hosted models.\n\n\n\nThe very idea of artificial “intelligence singularity” or its opposite is problematic from a scientific perspective where singularities are an indication that our theory is invalid at those scales. The fact that we so readily discuss “singularities” in the context of intelligence might indicate fundamental limitations in our current models of cognition and AI.\nWhile the rapid progress in AI is exciting, we must approach claims of AGI with caution. By viewing intelligence through the lens of complex systems, we gain a more nuanced understanding of the challenges ahead. Just as physicists continue to grapple with phenomena like turbulence, AI researchers must embrace the multifaceted nature of intelligence, developing new frameworks and approaches to capture its full complexity."
  },
  {
    "objectID": "posts/2024-06-15-intelligence-complex/index.html#introduction",
    "href": "posts/2024-06-15-intelligence-complex/index.html#introduction",
    "title": "Intelligence as a Complex System: Lessons from Physics",
    "section": "",
    "text": "In the rapidly evolving field of artificial intelligence, there’s a growing need to understand the nuances and complexities of intelligence itself. By drawing analogies from successful physical models of complex systems, we can gain valuable insights into the nature of intelligence and the challenges we face in replicating it. This essay explores the parallels between intelligence and other complex phenomena in physics, highlighting why simplistic approaches to AI may fall short of true artificial general intelligence (AGI)."
  },
  {
    "objectID": "posts/2024-06-15-intelligence-complex/index.html#the-complexity-spectrum",
    "href": "posts/2024-06-15-intelligence-complex/index.html#the-complexity-spectrum",
    "title": "Intelligence as a Complex System: Lessons from Physics",
    "section": "",
    "text": "Just as physical phenomena exhibit varying degrees of complexity, intelligence exists on a spectrum. Consider the following examples:\n\nTurbulence in fluid dynamics:\n\nSimple: Rayleigh–Bénard convection near the transition point.\nComplex: Plasma behavior around supermassive black holes (Reynolds number \\(\\sim 10^{20}\\)).\n\nIntelligence tasks:\n\nSimple: Grade school math problems.\nComplex: Developing groundbreaking scientific theories (e.g., the Ising model in ferromagnetism).\n\n\nThis spectrum illustrates that, like turbulence, we may not yet know if there’s an upper limit to intelligence. It also suggests that for many tasks, a simplified or “compressed” representation might suffice, explaining why some believe AGI has been achieved based on performance in limited domains. The complexity of turbulence is well characterized by the Reynolds number, but studies in the scaling laws of LLMs leaves a lot to be desired where claims of emergence are being made on simple datasets with fixed task complexity, input and output lengths. See Are Emergent Abilities of Large Language Models a Mirage? for a refreshing take on this."
  },
  {
    "objectID": "posts/2024-06-15-intelligence-complex/index.html#the-danger-of-hype-reductionist-thinking",
    "href": "posts/2024-06-15-intelligence-complex/index.html#the-danger-of-hype-reductionist-thinking",
    "title": "Intelligence as a Complex System: Lessons from Physics",
    "section": "",
    "text": "Historically, scientists have fallen into the trap of reductionism – the belief that complex phenomena can be fully explained by understanding their fundamental components. Paul Dirac’s 1929 statement exemplifies this:\n\n“The underlying physical laws necessary for the mathematical theory of a large part of physics and the whole of chemistry are thus completely known.” Source\n\nHowever, just as a unified theory of fundamental forces wouldn’t explain emergent phenomena in physics, a single AI model is unlikely to capture the full spectrum of intelligence. This reductionist thinking can lead to overestimating the capabilities of current AI models, which excel in specific tasks but struggle with generalization and complex reasoning."
  },
  {
    "objectID": "posts/2024-06-15-intelligence-complex/index.html#key-aspects-of-intelligence-as-a-complex-system",
    "href": "posts/2024-06-15-intelligence-complex/index.html#key-aspects-of-intelligence-as-a-complex-system",
    "title": "Intelligence as a Complex System: Lessons from Physics",
    "section": "",
    "text": "Dynamic nature: Intelligence is inherently non-equilibrium, dynamic, nonlinear, and high-dimensional. A static language model, no matter how advanced, cannot fully capture these aspects.\nHierarchical complexity: Like physical systems, intelligence requires flexible frameworks that allow for hierarchical representations. In physics, we have:\n\nN-particle descriptions (e.g., molecular dynamics)\nKinetic descriptions (e.g., Boltzmann, Vlasov equations)\nFluid descriptions (e.g., Navier-Stokes equations)\nMean field descriptions (e.g., filtered turbulent fields)\n\nAI research needs analogous frameworks to capture different levels of cognitive processes. However, one might argue that just like how one can use synthetic turbulence models through stochastic forcing to good effect for modeling unobserved physics across scales, GPT-like models with an analogus stochastic training process might be able to capture higher-level cognitive processes.\nMeta-frameworks for problem-solving: Current AI models lack robust strategies for approaching intractable problems. For instance, when experimental data is scarce or the physical system under consideration is extremely complex, breakthroughs in physics often came from constructing simplified models that capture the essence of complex phenomena (e.g., the Ising model for ferromagnetism).\nData limitations: Current AI models have almost no inductive biases and learn everything from the data, which has limitations:\n\nWeb-scale data has complex reasoning tasks only in their long-tail, which makes complex reasoning difficult to learn.\nDetailed reasoning steps are not available since humans only write down the final answer.\nEqual weighting of data samples is sub-optimal since only a fraction represent high-quality research and content.\nExamples from long-term scientific development are randomly distributed in the data and not systematically organized (e.g., the evolution of theories over decades).\n\nThe specific case of equal weighting of data is particularly problematic since many articles and books are written by people without adequate expertise and contain arguments without rigorous theoretical calculations and experimental results."
  },
  {
    "objectID": "posts/2024-06-15-intelligence-complex/index.html#the-unique-pace-of-ai-development",
    "href": "posts/2024-06-15-intelligence-complex/index.html#the-unique-pace-of-ai-development",
    "title": "Intelligence as a Complex System: Lessons from Physics",
    "section": "",
    "text": "Despite these challenges, AI research progresses at an unprecedented rate compared to other complex fields thanks to:\n\nImmediate access to state-of-the-art models through APIs and open-source libraries.\nEnhanced tooling for data ingestion and generation.\nThe ability to build upon existing work rapidly.\n\nContrast this with research in turbulence or computational fluid dynamics, where reproducing results can take years because of:\n\nComplex, million-line codebases in C, C++, Fortran.\nLimited access to high-performance computing.\nLack of open data sharing practices, and detailed model descriptions for reproducibility.\n\nAs an example, consider the difficulty in generating \\(1000\\) time steps for a turbulent flow simulation and contrast it with generating \\(1000\\) tokens in language models through the interface, API or locally hosted models."
  },
  {
    "objectID": "posts/2024-06-15-intelligence-complex/index.html#conclusion",
    "href": "posts/2024-06-15-intelligence-complex/index.html#conclusion",
    "title": "Intelligence as a Complex System: Lessons from Physics",
    "section": "",
    "text": "The very idea of artificial “intelligence singularity” or its opposite is problematic from a scientific perspective where singularities are an indication that our theory is invalid at those scales. The fact that we so readily discuss “singularities” in the context of intelligence might indicate fundamental limitations in our current models of cognition and AI.\nWhile the rapid progress in AI is exciting, we must approach claims of AGI with caution. By viewing intelligence through the lens of complex systems, we gain a more nuanced understanding of the challenges ahead. Just as physicists continue to grapple with phenomena like turbulence, AI researchers must embrace the multifaceted nature of intelligence, developing new frameworks and approaches to capture its full complexity."
  },
  {
    "objectID": "consulting/2025-04-13-AI-fashion/index.html",
    "href": "consulting/2025-04-13-AI-fashion/index.html",
    "title": "AI for second-hand fashion",
    "section": "",
    "text": "OUTCOME: 40% reduction in manual processing time with 50%+ decrease in data collection costs through innovative synthetic data techniques."
  },
  {
    "objectID": "consulting/2025-04-13-AI-fashion/index.html#business-context",
    "href": "consulting/2025-04-13-AI-fashion/index.html#business-context",
    "title": "AI for second-hand fashion",
    "section": "1. Business Context",
    "text": "1. Business Context\nManual quality inspection created major bottlenecks in circular fashion supply chains, with 30% inconsistency in assessments and excessive labor costs driving up prices by 25%. The industry needed automation to scale sustainable fashion initiatives."
  },
  {
    "objectID": "consulting/2025-04-13-AI-fashion/index.html#solution-snapshot-24-months",
    "href": "consulting/2025-04-13-AI-fashion/index.html#solution-snapshot-24-months",
    "title": "AI for second-hand fashion",
    "section": "2. Solution Snapshot (24 Months)",
    "text": "2. Solution Snapshot (24 Months)\n\n\n\nComponent\nWhat We Built\nTechnologies\n\n\n\n\nData Infrastructure\nCustom dual-camera capture system with specialized annotation platform\nFlask APIs, Streamlit UI, RESTful backend\n\n\nDataset Enhancement\nQuality control & balancing for 30,000+ images; metadata enrichment\nCustom processing apps, Pytorch\n\n\nCV Model Architecture\nState-of-the-art attribute detection with 92% accuracy on primary categories\nConvNeXt, Vision Transformers (ViT) & CLIP variants\n\n\nSynthetic Data Pipeline\nInpainting framework to generate realistic damage patterns for object detection\nPrompt engineering, Automated mask generation\n\n\nDeployment System\nWeb-based interface for real-time attribute detection\nGradio"
  },
  {
    "objectID": "consulting/2025-04-13-AI-fashion/index.html#impact",
    "href": "consulting/2025-04-13-AI-fashion/index.html#impact",
    "title": "AI for second-hand fashion",
    "section": "3. Impact",
    "text": "3. Impact\n\n40% reduction in manual inspection processing time.\n50%+ decrease in data collection costs through synthetic data generation.\n92% accuracy on primary damage categories despite challenging long-tailed data.\nCreated one of a kind public dataset for fashion attribute detection research.\nSelected as 1 of only 5 projects presented at EU sustainable AI summit (2023)."
  },
  {
    "objectID": "consulting/2025-04-13-AI-fashion/index.html#my-role",
    "href": "consulting/2025-04-13-AI-fashion/index.html#my-role",
    "title": "AI for second-hand fashion",
    "section": "4. My Role",
    "text": "4. My Role\n\nLed end-to-end project management for €1M AI initiatives across two major programs (AI for Circular Fashion, CISUTAC).\nDesigned technical architecture and coordinated cross-functional implementation.\nPersonally implemented key components of synthetic data generation pipeline.\nDelivered presentations at Vinnova Innovation Week (2022) and EU sustainable AI (2023)."
  },
  {
    "objectID": "consulting/2025-04-13-AI-fashion/index.html#next-steps",
    "href": "consulting/2025-04-13-AI-fashion/index.html#next-steps",
    "title": "AI for second-hand fashion",
    "section": "5. Next Steps",
    "text": "5. Next Steps\nRead more here.\n\nNeed to automate your quality inspection processes using AI? → Book a consultation"
  }
]